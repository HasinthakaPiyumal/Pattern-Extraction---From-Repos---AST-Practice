{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cf20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "\n",
    "def get_embedding_model():\n",
    "    return GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "\n",
    "def generate_embeddings(texts):\n",
    "    embedding_model = get_embedding_model()\n",
    "    embeddings = embedding_model.embed_documents(texts)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059b643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"The Judicial Panel Pattern\n",
    "üßê Problem\n",
    "How do you perform a complex evaluation or make a decision that requires multiple, diverse criteria to be assessed simultaneously? A single, monolithic evaluation function can become incredibly complex, difficult to maintain, and hard to extend. For instance, evaluating the quality of an AI's response involves checking for factual accuracy, tone, safety, clarity, and helpfulness. Combining all this logic into one place is brittle. Similarly, in traditional systems like loan processing, you need to check credit history, income stability, and fraud risk, which are distinct areas of expertise.\n",
    "\n",
    "üí° Solution\n",
    "The Judicial Panel pattern provides a solution by decoupling the evaluation criteria into a collection of specialized, independent components called Judges. Each Judge is an expert in one specific area. A coordinating entity, the SuperJudge, acts as a Mediator. It doesn't perform evaluations itself but instead gathers the \"verdicts\" from all the individual Judges and synthesizes them into a single, final output.\n",
    "\n",
    "This structure is evident in the repository:\n",
    "\n",
    "ConcreteJudge: Represents a specialized evaluator. Each instance would be configured with a specific goal or \"metaprompt\" to assess one facet of a problem.\n",
    "\n",
    "JudgeFactory: A factory for creating the required Judge instances for a given task, based on a configuration (Assembly).\n",
    "\n",
    "SuperJudge: Implements the Mediator pattern. It has a register_judge method to enlist the individual evaluators and a notify method for each Judge to report its findings. Its final_verdict method aggregates these findings into a cohesive summary.\n",
    "\n",
    "JudgeOrchestrator: The high-level component that initiates the entire process.\n",
    "\n",
    "The process works as follows:\n",
    "\n",
    "The JudgeOrchestrator receives a request.\n",
    "\n",
    "It uses the JudgeFactory to create a panel of ConcreteJudge agents and a SuperJudge.\n",
    "\n",
    "Each ConcreteJudge independently performs its evaluation, potentially using external tools or Plugins (like the StatisticalAnalysisPlugin).\n",
    "\n",
    "Each Judge reports its findings to the SuperJudge.\n",
    "\n",
    "The SuperJudge consolidates all the reports into a final, comprehensive verdict.\n",
    "\n",
    "üöÄ Applicability & Reusability\n",
    "This pattern is highly reusable and valuable for traditional software projects beyond its AI origins. It provides a clean, extensible architecture for any system requiring complex, multi-criteria decision-making.\n",
    "\n",
    "Financial Services: In a loan approval system, you could have a CreditScoreJudge, an IncomeVerificationJudge, and a FraudDetectionJudge. The SuperJudge would aggregate their reports to make a final approve/deny decision.\n",
    "\n",
    "Automated Content Moderation: Instead of one complex filter, you can deploy a HateSpeechJudge, a SpamJudge, and a PIIJudge (Personally Identifiable Information). The panel's final verdict determines if the content is published.\n",
    "\n",
    "System Diagnostics: To monitor the health of a complex application, you can have a DatabaseHealthJudge, a NetworkLatencyJudge, and an ApplicationLogJudge. The SuperJudge provides a holistic view of the system's status.\n",
    "\n",
    "E-commerce: When a new product is uploaded, different judges can validate the image quality (ImageJudge), check the description for prohibited keywords (DescriptionJudge), and verify the pricing against business rules (PricingJudge).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "849768f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"\n",
    "üß† What Is \"LLM as Judge\"?\n",
    "\n",
    "In this pattern, an LLM is tasked with evaluating outputs from other AI models or agents. The evaluation is guided by specific instructions embedded in the prompt, such as assessing factual accuracy, tone, coherence, or adherence to guidelines. This method is particularly useful for quality assurance, model benchmarking, and safety monitoring in production environments. \n",
    "Evidently AI\n",
    "\n",
    "üîÑ How It Works\n",
    "\n",
    "Input Processing: The system collects outputs from AI agents or models, which may include text, code, or responses.\n",
    "\n",
    "Evaluation Prompting: An LLM is prompted to assess the collected outputs based on defined criteria.\n",
    "\n",
    "Scoring and Reasoning: The LLM provides a score (e.g., 1‚Äì10) along with a rationale for its assessment.\n",
    "\n",
    "Feedback Loop: The evaluation results are used to refine the AI models, update training data, or adjust system behavior.\n",
    "\n",
    "This process can be automated to continuously monitor and improve AI system performance.\n",
    "\n",
    "üß© Design Patterns and Architectures\n",
    "\n",
    "Implementing \"LLM as Judge\" involves several design considerations:\n",
    "\n",
    "Evaluation Granularity: Breaking down tasks into smaller components allows for more precise evaluations and reduces ambiguity. \n",
    "Confident AI\n",
    "\n",
    "Multi-Agent Collaboration: Utilizing multiple LLMs can provide diverse perspectives and enhance evaluation robustness.\n",
    "\n",
    "Human-in-the-Loop: Incorporating human oversight at critical points ensures that evaluations align with ethical standards and domain expertise. \n",
    "Medium\n",
    "\n",
    "‚öôÔ∏è Practical Applications\n",
    "\n",
    "Automated Content Moderation: Assessing user-generated content for compliance with community guidelines.\n",
    "\n",
    "Model Benchmarking: Comparing the performance of different AI models or versions.\n",
    "\n",
    "Safety Monitoring: Detecting and mitigating harmful or biased outputs in AI systems.\n",
    "\n",
    "These applications are particularly relevant in industries where content quality and safety are paramount, such as social media platforms, customer service, and healthcare.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1f7dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"\"\"\n",
    "from call_graph_generator import build_call_graph\n",
    "from repo_structure_extractor import extract_repo_structure\n",
    "import json\n",
    "import os\n",
    "from utils import save_json\n",
    "    \n",
    "    def extract_structure(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "                The Judicial Panel Pattern\n",
    "                m\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c11bd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a6af907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760611038.973579  103540 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760611038.975140  103540 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8714339009011423\n"
     ]
    }
   ],
   "source": [
    "embs = generate_embeddings([text1,text2])\n",
    "np_emb1 = np.array(embs[0])\n",
    "np_emb2 = np.array(embs[1])\n",
    "print(cosine_similarity([np_emb1], [np_emb2])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb74ad40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760611113.427258  103540 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760611113.429074  103540 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7524981720667041\n"
     ]
    }
   ],
   "source": [
    "embs = generate_embeddings([text1,text3])\n",
    "np_emb1 = np.array(embs[0])\n",
    "np_emb2 = np.array(embs[1])\n",
    "print(cosine_similarity([np_emb1], [np_emb2])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c39af854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760611115.568116  103540 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760611115.569513  103540 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6899585992138212\n"
     ]
    }
   ],
   "source": [
    "embs = generate_embeddings([text2,text3])\n",
    "np_emb1 = np.array(embs[0])\n",
    "np_emb2 = np.array(embs[1])\n",
    "print(cosine_similarity([np_emb1], [np_emb2])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6254a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
